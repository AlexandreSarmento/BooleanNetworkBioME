{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "K_means binarization.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AlexandreSarmento/BooleanNetworkBioME/blob/master/K_means_binarization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GPksdL0lre8w"
      },
      "source": [
        "# BINARIZATION THROUGH CLUSTERING METHODS NOTEBOOK\n",
        "### Here we are adapting a previously developed approach called iterative k-means binarization with a clustering depth (d) of 1 (KM1) or 2 (KM2) or 3 (KM3). The number of cluster (k) must be greater than the number of experimental measurement (n) k > n. It's well know that k = 2**d, therefore, here concerning to the experimental data provided by database we set d = 2, so k = 4. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "csKnX6DHsfaa"
      },
      "source": [
        "## Instaling Packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eSdriPo2rSth",
        "outputId": "f4b6c588-d5b7-4c46-aa5c-af8c53d1b4b9"
      },
      "source": [
        "!pip3 install biopython"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: biopython in /usr/local/lib/python3.7/dist-packages (1.79)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from biopython) (1.19.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QMdATC5HrZ45",
        "outputId": "1b15c398-2f0b-4728-ac57-57600f25ad2b"
      },
      "source": [
        "!pip install bitarray"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting bitarray\n",
            "  Downloading bitarray-2.3.4.tar.gz (88 kB)\n",
            "\u001b[?25l\r\u001b[K     |███▊                            | 10 kB 22.3 MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 20 kB 29.1 MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 30 kB 22.6 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 40 kB 18.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 51 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 61 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 71 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 81 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 88 kB 4.2 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: bitarray\n",
            "  Building wheel for bitarray (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bitarray: filename=bitarray-2.3.4-cp37-cp37m-linux_x86_64.whl size=171949 sha256=661d0348f3fefeaeb0789e32835f599f77fc8ca9dbd6479ae3475e9d3a36365a\n",
            "  Stored in directory: /root/.cache/pip/wheels/84/cc/5b/0e861bdb5294d22d2d4f595df936f964a95258387e11494d41\n",
            "Successfully built bitarray\n",
            "Installing collected packages: bitarray\n",
            "Successfully installed bitarray-2.3.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ckVD2g0s3Oq"
      },
      "source": [
        "## Importing Modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7AbakKKLsxqJ"
      },
      "source": [
        "import math, numpy, sys\n",
        "from bitarray import bitarray\n",
        "import csv, array\n",
        "from Bio import Cluster # importar Biopython\n",
        "import os\n",
        "import shutil"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yo7akWMGvOeC"
      },
      "source": [
        "## Setting variables to proxy time serie binarization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3PNS6KxSt7Cu"
      },
      "source": [
        "number_of_folders = 25\n",
        "counterF=1\n",
        "while counterF <= number_of_folders:\n",
        "    os.mkdir('proxy_results{}'.format(str(counterF)))\n",
        "    counterF += 1 "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wTo9hW8Jj1YJ"
      },
      "source": [
        "inputFileName = []  \n",
        "outputFileName = []\n",
        "KMX = 3\n",
        "number_of_bin = 100*5\n",
        "ID_of_group = list(range(1,number_of_folders+1))\n",
        "for loop in ID_of_group:\n",
        "  \n",
        "  inputFileName.append('/content/grupo'+str(loop)+'_')\n",
        "  outputFileName.append('/content/proxy_results'+str(loop)+'/proxy_grupo'+str(loop)+'_')\n",
        "\n",
        "originalSeries = {}    # original series stored here as a list\n",
        "binarySeries = {}    # structure same as the original but with binary series\n",
        "inputoutput = {} "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iYgHa60AvcK7"
      },
      "source": [
        "# setting variables to experimental time serie binarization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6mgcAh06vZMT"
      },
      "source": [
        "!mkdir breast_results\n",
        "number_of_bin = 3\n",
        "KMX = 2\n",
        "inputFileName = '/content/breast_raw_data2_'\n",
        "outputFileName = '/content/breast_results/breast_raw_data2_'\n",
        "originalSeries = {}    # original series stored here as a list\n",
        "binarySeries = {}    # structure same as the original but with binary series\n",
        "inputoutput = {} # keys are combinations, with a list of compbinations that are outputs of it "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gw6RJU3P0kQ9"
      },
      "source": [
        "def decrementalKMeanBinarization(orig, clusters, reduction=0):    \n",
        "    clusterData = {}\n",
        "    clusterRes = {}\n",
        "    binSeries = {}\n",
        "    if clusters < 2:\n",
        "            return None\n",
        "    while clusters >= 2:\n",
        "            # 'NON' allows you to ignore specific species \n",
        "            for k,v in list(orig.items()):\n",
        "                    if k == \"NON\":\n",
        "                            continue\n",
        "                    data = []\n",
        "                    for i in range(len(v)):\n",
        "                            row = [i,v[i]]\n",
        "                            data.append(row)\n",
        "                    x = numpy.vstack(v)\n",
        "                    clusterData[k] = x\n",
        "                                        # Bio.Cluster.kcluster()\n",
        "                    idx, error, nfound = Cluster.kcluster(x, nclusters=clusters, method='a', dist='e')\n",
        "                    clusterRes[k] = (idx, error, nfound)\n",
        "\n",
        "            # replace the values with the averages of the clusters\n",
        "            for k,r in list(clusterRes.items()):\n",
        "                    colors = []\n",
        "                    idx, error, nfound = r\n",
        "                    y = clusterData[k]\n",
        "                    x = numpy.arange(len(y))\n",
        "                    sizes = {}\n",
        "                    sums = {}\n",
        "                    for i in range(clusters):\n",
        "                            sizes[i] = 0\n",
        "                            sums[i] = 0\n",
        "                    for i in range(len(idx)):\n",
        "                            sizes[idx[i]] += 1\n",
        "                            sums[idx[i]] += y[i]\n",
        "                    # culculate sums\n",
        "                    for i in list(sums.keys()):\n",
        "                            sums[i] /= sizes[i]\n",
        "                            \n",
        "                    # replace all the values with sums in the clusters\n",
        "                    averaged = []\n",
        "                    for i in idx:\n",
        "                            averaged.append(sums[i][0])\n",
        "                    orig[k] = averaged\n",
        "\n",
        "            clusters //= 2\n",
        "    # replace data with 0 and 1\n",
        "    for k,v in list(orig.items()):\n",
        "            if k == \"NON\":\n",
        "                    continue\n",
        "            mi = min(v)\n",
        "            binVals = bitarray()\n",
        "            for i in v:\n",
        "                    if i == mi:\n",
        "                            binVals.append(False)\n",
        "                    else:\n",
        "                            binVals.append(True)\n",
        "            binSeries[k] = binVals\n",
        "  \n",
        "    return binSeries"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qXUrWVs6zuje"
      },
      "source": [
        "# Main script to generate proxy time serie binarization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EwKTcCCl1PMa"
      },
      "source": [
        "for loopG in range(len(ID_of_group)):\n",
        "    \n",
        "    print \"Group: \" + str(loopG)\n",
        "    \n",
        "    for loopB in range(number_of_bin):\n",
        "        \n",
        "        print(str(loopB) + \" of \" + str(number_of_bin))\n",
        "        bMethod = KMX \n",
        "        #Reduction methods\n",
        "        reduction = 0\n",
        "        print(inputFileName[loopG])\n",
        "        csvfile = open(inputFileName[loopG] +'.csv', 'r') \n",
        "        r = csv.reader(csvfile)\n",
        "        topLine = next(r)\n",
        "        #topLine = r.next()\n",
        "        order = []\n",
        "        # grabs each species, \n",
        "        for t in topLine:\n",
        "                # creates an empty list for each species\n",
        "                originalSeries[t] = []\n",
        "                order.append(t)\n",
        "        for line in r:\n",
        "                if line[0].startswith(\"#\"):\n",
        "                        continue\n",
        "                words = line\n",
        "                # fills the array for each species with the original data points\n",
        "                for i in range(len(words)):\n",
        "                        originalSeries[order[i]].append(float(words[i]))\n",
        "        allConvergence = []\n",
        "        allTimes = []\n",
        "        # determines cluster depth (d). Number of clusters, k = 2^d \n",
        "        if bMethod > 0:\n",
        "            clusters = int(math.pow(2,bMethod))\n",
        "            binarySeries = decrementalKMeanBinarization(dict(originalSeries), clusters, reduction)\n",
        "        for i in binarySeries:\n",
        "            sampleSize2= len(binarySeries[i])\n",
        "        # write binarized data to file\n",
        "        f = open(outputFileName[loopG] + str(loopB) + '.csv', \"wb\")\n",
        "        for item in binarySeries:\n",
        "            f.write(bytes(item,'utf-8'))\n",
        "            #f.write(str(item))\n",
        "            values = str(binarySeries[item])\n",
        "            values  = values.rstrip(')')\n",
        "            values = values.rsplit('bitarray(')\n",
        "            values = values[1]\n",
        "            values = values.lstrip('\\'')\n",
        "            values = values.rstrip('\\'')\n",
        "            valueList = list(values)\n",
        "            #tmp[1]\n",
        "            for sample in valueList:\n",
        "                f.write(bytes(\",\" + sample,'utf-8'))\n",
        "                #f.write(\",\" + str(sample))\n",
        "            #print(str(valueList)+',')\n",
        "            f.write(bytes(\"\\n\",'utf-8'))\n",
        "    \n",
        "        # Close opened file\n",
        "        f.close() "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "girbURizz5r0"
      },
      "source": [
        "# Main Script to generate experimental time serie binarization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2AyFsL0Iz4j8"
      },
      "source": [
        "counter = 0\n",
        "while (counter < number_of_bin):\n",
        "    counter += 1\n",
        "    print((str(counter) + \" of \" + str(number_of_bin) + \"binarizations\"))\n",
        "    bMethod = KMX\n",
        "    #Reduction methods\n",
        "    reduction = 0\n",
        "    csvfile = open(inputFileName +'.csv', 'r') \n",
        "    r = csv.reader(csvfile)\n",
        "    \n",
        "    topLine = next(r)\n",
        "    order = []\n",
        "    # grabs each species, \n",
        "    for t in topLine:\n",
        "            # creates an empty list for each species\n",
        "            originalSeries[t] = []\n",
        "            order.append(t)\n",
        "    for line in r:\n",
        "            if line[0].startswith(\"#\"):\n",
        "                    continue\n",
        "            words = line\n",
        "            # fills the array for each species with the original data points\n",
        "            for i in range(len(words)):\n",
        "                    originalSeries[order[i]].append(float(words[i]))\n",
        "    allConvergence = []\n",
        "    allTimes = []\n",
        "    # determines cluster depth (d). Number of clusters, k = 2^d \n",
        "    if bMethod > 0:\n",
        "        clusters = int(math.pow(2,bMethod))\n",
        "        binarySeries = decrementalKMeanBinarization(dict(originalSeries), clusters, reduction)\n",
        "    for i in binarySeries:\n",
        "        sampleSize2= len(binarySeries[i])\n",
        "    # write binarized data to file\n",
        "    f = open(outputFileName + str(counter) + '.csv', \"wb\")\n",
        "    for item in binarySeries:\n",
        "        f.write(bytes(item,'utf-8'))\n",
        "        values = str(binarySeries[item])\n",
        "        values  = values.rstrip(')')\n",
        "        values = values.rsplit('bitarray(')\n",
        "        values = values[1]\n",
        "        values = values.lstrip('\\'')\n",
        "        values = values.rstrip('\\'')\n",
        "        valueList = list(values)\n",
        "        for sample in valueList:\n",
        "            f.write(bytes(\",\" + sample,'utf-8'))\n",
        "            #f.write(\",\" + str(sample))\n",
        "        f.write(bytes(\"\\n\",'utf-8'))\n",
        "\n",
        "    f.close() "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qRqUYkVzwCyZ"
      },
      "source": [
        "## create or delete zip folders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KEZkL6DhPARd"
      },
      "source": [
        "# here we are creating zip folders to each proxy group of input parameters binarization\n",
        "for x in ID_of_group:\n",
        "  shutil.make_archive('/content/proxy_results'+str(x), 'zip', '/content/proxy_results'+str(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2rtJhFqxxMAI"
      },
      "source": [
        "# here we are deleting zip folders to each proxy group of input parameters binarization\n",
        "for j in ID_of_group:\n",
        "  shutil.rmtree('/content/proxy_results'+str(j), ignore_errors=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hbgyVKfHwQLY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d7565313-bed4-4d2a-b6a2-21e9d295e68e"
      },
      "source": [
        "# here we are creating zip folders to breast time serie binarization\n",
        "shutil.make_archive('/content/breast_results', 'zip', '/content/breast_results')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/breast_results.zip'"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rcSCirCsxP9G"
      },
      "source": [
        "# here we are deleting zip folders to breast time serie binarization\n",
        "shutil.rmtree('/content/glioma_results')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m_n_Uak67sZq"
      },
      "source": [
        "!rm *.csv\n",
        "!rm -rf *.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rWpKO82vrVfZ"
      },
      "source": [
        "%reset"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}